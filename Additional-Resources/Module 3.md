# Topics & Resources

Convolutional neural networks (CNN)
- https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53 

ReLU activation function
- https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/ 

Weight initialization
- https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79 

Batch normalization and drop out
- https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd

Vanishing gradient
- https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484 

CNN architectures
- https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d 

Transfer learning
- https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a 

Hands-On Tutorials
- https://www.tensorflow.org/tutorials/images/cnn
- https://towardsdatascience.com/covolutional-neural-network-cb0883dd6529#:~:text=Examples%20of%20CNN%20in%20computer,i.e%2C%20weights%2C%20biases%20etc.
